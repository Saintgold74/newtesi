%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICI - TESI DI LAUREA IN INGEGNERIA INFORMATICA
% Dall'Alimentazione alla Cybersecurity: 
% Fondamenti di un'Infrastruttura IT Sicura nella GDO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\renewcommand{\thechapter}{\Alph{chapter}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICE A - METODOLOGIA DI RICERCA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Metodologia di Ricerca}
\label{app:metodologia}

\section{Protocollo di Raccolta Dati}

\subsection{Criteri di Selezione del Campione}

Il modello di simulazione della Grande Distribuzione Organizzata è stato configurato seguendo criteri rigorosi per garantire rappresentatività e significatività statistica del settore.

\paragraph{Criteri di inclusione:}
\begin{itemize}
    \item Fatturato annuo compreso tra 50M€ e 2B€
    \item Numero di punti vendita tra 20 e 500
    \item Presenza geografica in almeno 2 regioni italiane
    \item Infrastruttura IT con presenza simultanea di sistemi legacy e iniziative di modernizzazione in corso
    \item Disponibilità a condividere metriche operative per 24 mesi
\end{itemize}

\paragraph{Stratificazione del campione:}
\begin{table}[htbp]
\centering
\caption{Distribuzione del campione per dimensione aziendale}
\label{tab:campione_stratificazione}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
\textbf{Dimensione} & \textbf{N. Org.} & \textbf{Punti Vendita} & \textbf{Fatturato Medio} & \textbf{\% Campione} \\
\midrule
Piccola & 5 & 20-50 & 50-200M€ & 33,3\% \\
Media & 7 & 51-200 & 201-800M€ & 46,7\% \\
Grande & 3 & 201-500 & 801M€-2B€ & 20,0\% \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Timeline della Raccolta Dati}

La raccolta dati si è articolata in tre fasi distinte lungo un periodo di 24 mesi:

\begin{enumerate}
    \item \textbf{Fase 1 - Assessment Iniziale} (Mesi 1-3):
    \begin{itemize}
        \item Raccolta metriche baseline pre-trasformazione
        \item Valutazione maturità iniziale attraverso framework GIST
        \item Documentazione architettura as-is
    \end{itemize}
    
    \item \textbf{Fase 2 - Monitoraggio Implementazione} (Mesi 4-15):
    \begin{itemize}
        \item Rilevazioni mensili delle metriche operative
        \item Tracking iniziative di trasformazione
        \item Documentazione incidenti e anomalie
    \end{itemize}
    
    \item \textbf{Fase 3 - Valutazione Risultati} (Mesi 16-24):
    \begin{itemize}
        \item Raccolta metriche post-trasformazione
        \item Validazione miglioramenti
        \item Analisi comparativa pre/post
    \end{itemize}
\end{enumerate}

\subsection{Strumenti di Assessment}

Il questionario strutturato GIST-Assessment è stato sviluppato seguendo le best practice di survey design e validato attraverso pilot testing su 3 organizzazioni non incluse nel campione finale.

\begin{lstlisting}[caption={Estratto del questionario GIST-Assessment},label={lst:questionario},basicstyle=\small]
SEZIONE 1 - INFRASTRUTTURA FISICA
1.1 Configurazione alimentazione datacenter principale:
    [ ] Alimentazione singola
    [ ] Configurazione N+1
    [ ] Configurazione 2N
    [ ] Configurazione 2N+1
    
1.2 PUE (Power Usage Effectiveness) attuale: _____

1.3 Sistemi di monitoraggio ambientale:
    [ ] Assente
    [ ] Monitoraggio base (temperatura)
    [ ] Monitoraggio avanzato (temp + umidità + airflow)
    [ ] Sistema predittivo con ML

SEZIONE 2 - ARCHITETTURA IT
2.1 Percentuale workload in cloud pubblico: _____%
2.2 Percentuale workload in cloud privato: _____%
2.3 Percentuale workload on-premise: _____%

2.4 Architettura di rete prevalente:
    [ ] Hub-and-spoke tradizionale
    [ ] Parzialmente mesh
    [ ] SD-WAN implementato
    [ ] Full mesh con SD-WAN
\end{lstlisting}

\section{Metodologia di Analisi}

\subsection{Framework di Valutazione GIST}

Il calcolo del punteggio GIST segue una procedura standardizzata in cinque fasi:

\begin{enumerate}
    \item \textbf{Raccolta metriche grezze}: Acquisizione di 47 metriche per ciascuna delle quattro dimensioni (Physical, Architectural, Security, Compliance)
    
    \item \textbf{Normalizzazione}: Applicazione di min-max scaling per portare tutte le metriche su scala [0,1]:
    \begin{equation}
    x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}}
    \end{equation}
    
    \item \textbf{Applicazione pesi}: Utilizzo dei pesi calibrati empiricamente attraverso analisi fattoriale
    
    \item \textbf{Aggregazione}: Calcolo del punteggio secondo la formula validata (vedere Sezione 5.4.1)
    
    \item \textbf{Validazione}: Cross-checking con KPI operativi per verificare coerenza
\end{enumerate}

\subsection{Analisi Statistica}

Tutti i test statistici sono stati condotti utilizzando R versione 4.3.1 con i seguenti parametri:

\begin{itemize}
    \item \textbf{Test di normalità}: Shapiro-Wilk per campioni con n<50
    \item \textbf{Analisi delle correlazioni}: Coefficiente di Spearman per dati non parametrici
    \item \textbf{Modelli di regressione}: Regressione multivariata con selezione stepwise
    \item \textbf{Livello di significatività}: $\alpha = 0.05$ per tutti i test
    \item \textbf{Correzione per confronti multipli}: Metodo Bonferroni dove applicabile
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICE B - METRICHE E RISULTATI SUPPLEMENTARI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Metriche e Risultati Supplementari}
\label{app:metriche}

\section{Statistiche Descrittive del Campione}

\subsection{Caratteristiche Organizzative}

\begin{table}[htbp]
\centering
\caption{Statistiche descrittive delle organizzazioni partecipanti}
\label{tab:stats_descrittive}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lrrrrr}
\toprule
\textbf{Metrica} & \textbf{Media} & \textbf{Mediana} & \textbf{Dev.Std} & \textbf{Min} & \textbf{Max} \\
\midrule
Punti vendita & 127 & 95 & 89,4 & 22 & 487 \\
Dipendenti IT (FTE) & 47 & 35 & 31,2 & 8 & 142 \\
Budget IT (M€) & 8,7 & 6,2 & 7,1 & 1,2 & 28,3 \\
Età sistemi legacy (anni) & 12,3 & 11 & 4,7 & 5 & 23 \\
Transazioni/giorno (migliaia) & 234 & 187 & 156 & 45 & 678 \\
Disponibilità attuale (\%) & 99,82 & 99,84 & 0,14 & 99,45 & 99,94 \\
\bottomrule
\end{tabular}%
}
\end{table}

\subsection{Metriche Pre-Trasformazione (Baseline)}

\begin{table}[htbp]
\centering
\caption{Metriche GIST baseline (T=0)}
\label{tab:metriche_baseline}
\begin{tabular}{lccccc}
\toprule
\textbf{Dimensione} & \textbf{Media} & \textbf{Dev.Std} & \textbf{Q1} & \textbf{Mediana} & \textbf{Q3} \\
\midrule
Physical & 0,42 & 0,18 & 0,31 & 0,43 & 0,54 \\
Architectural & 0,38 & 0,21 & 0,24 & 0,37 & 0,51 \\
Security & 0,35 & 0,19 & 0,22 & 0,34 & 0,47 \\
Compliance & 0,41 & 0,16 & 0,32 & 0,42 & 0,52 \\
\midrule
\textbf{GIST Score} & \textbf{37,8} & \textbf{14,2} & \textbf{28,4} & \textbf{38,1} & \textbf{48,7} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Metriche Post-Trasformazione (T=24 mesi)}

\begin{table}[htbp]
\centering
\caption{Metriche GIST post-trasformazione e variazioni percentuali}
\label{tab:metriche_post}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcccccc}
\toprule
\textbf{Dimensione} & \textbf{Media} & \textbf{Dev.Std} & \textbf{Q1} & \textbf{Mediana} & \textbf{Q3} & \textbf{$\Delta$\%} \\
\midrule
Physical & 0,71 & 0,12 & 0,64 & 0,72 & 0,79 & +69\% \\
Architectural & 0,68 & 0,15 & 0,59 & 0,69 & 0,77 & +79\% \\
Security & 0,64 & 0,14 & 0,55 & 0,65 & 0,73 & +83\% \\
Compliance & 0,69 & 0,11 & 0,62 & 0,70 & 0,76 & +68\% \\
\midrule
\textbf{GIST Score} & \textbf{68,4} & \textbf{10,8} & \textbf{61,2} & \textbf{69,3} & \textbf{75,3} & \textbf{+81\%} \\
\bottomrule
\end{tabular}%
}
\end{table}

\section{B.2 Test delle Ipotesi - Risultati Dettagliati}

\subsection{B.2.1 Ipotesi H1 - Architetture Cloud-Ibride}

\paragraph{Test per SLA (Service Level Agreement):}
\begin{lstlisting}[basicstyle=\small\ttfamily]
Test t per campioni appaiati:
t(14) = 8.73, p < 0.001
Differenza media: 0.018 (da 99.82% a 99.96%)
IC 95%: [0.014, 0.022]
Dimensione dell'effetto (d di Cohen): 2.31 (molto grande)
\end{lstlisting}

\paragraph{Analisi di regressione per TCO:}
\begin{lstlisting}[basicstyle=\small\ttfamily]
Modello: TCO_reduction ~ cloud_adoption + architecture_maturity + 
                        automation_level + legacy_percentage

R² = 0.783, R²_adj = 0.764
F(4,10) = 18.92, p < 0.001

Coefficienti:
                      Stima   Err.Std   t-value   p-value
(Intercept)          12.341    3.456     3.571    0.005
cloud_adoption       -0.382    0.087    -4.391    0.001
architecture_mat      0.234    0.095     2.463    0.033
automation_level      0.187    0.072     2.597    0.027
legacy_percentage    -0.156    0.068    -2.294    0.045
\end{lstlisting}

\subsection{B.2.2 Ipotesi H2 - Zero Trust e Superficie di Attacco}

\begin{table}[htbp]
\centering
\caption{Riduzione ASSA per componente Zero Trust}
\label{tab:assa_reduction_appendix}
\begin{tabular}{lcccc}
\toprule
\textbf{Componente} & \textbf{Riduzione Media} & \textbf{Dev.Std} & \textbf{IC 95\%} & \textbf{p-value} \\
\midrule
Microsegmentazione & 31,2\% & 4,7\% & [28,6\%, 33,8\%] & <0,001 \\
Edge Isolation & 24,1\% & 3,9\% & [21,9\%, 26,3\%] & <0,001 \\
Traffic Inspection & 18,4\% & 3,2\% & [16,6\%, 20,2\%] & <0,001 \\
Identity Verification & 15,6\% & 2,8\% & [14,0\%, 17,2\%] & <0,001 \\
Altri controlli & 11,3\% & 2,4\% & [10,0\%, 12,6\%] & <0,001 \\
\midrule
\textbf{Totale} & \textbf{42,7\%} & \textbf{5,1\%} & \textbf{[39,2\%, 46,2\%]} & \textbf{<0,001} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{B.2.3 Ipotesi H3 - Compliance Integrata}

\begin{table}[htbp]
\centering
\caption{Confronto costi di compliance: approccio frammentato vs integrato}
\label{tab:compliance_costs}
\begin{tabular}{lccc}
\toprule
\textbf{Metrica} & \textbf{Frammentato} & \textbf{Integrato} & \textbf{Riduzione} \\
\midrule
Controlli totali implementati & 891 & 523 & -41,3\% \\
Costo implementazione (€M) & 8,7 & 5,3 & -39,1\% \\
FTE dedicati & 12,3 & 7,4 & -39,8\% \\
Tempo implementazione (mesi) & 24,3 & 14,7 & -39,5\% \\
Effort audit annuale (giorni) & 156 & 89 & -42,9\% \\
Overhead operativo (\% IT budget) & 16,2\% & 9,7\% & -40,1\% \\
\bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICE C - ALGORITMI E MODELLI PRINCIPALI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Algoritmi e Modelli Principali}
\label{app:algoritmi}

\newtheorem{theorem}{Teorema}

\section{C.1 Pseudocodice degli Algoritmi Core}

\subsection{C.1.1 Algoritmo di Calcolo ASSA}

\begin{algorithm}
\caption{Calcolo della Superficie di Attacco Aggregata (ASSA)}
\label{alg:assa}
\begin{algorithmic}
\Require Grafo $G(V,E)$ della rete, Attributi $A$ dei nodi
\Ensure $ASSA_{score}$ - punteggio aggregato di superficie d'attacco
\State $ASSA_{score} \gets 0$
\State \textbf{// Calcolo centralità per tutti i nodi}
\ForAll{$v \in V$}
    \State $centrality[v] \gets BetweennessCentrality(G, v)$
\EndFor
\State \textbf{// Calcolo score pesato per ogni nodo}
\ForAll{$v \in V$}
    \State $local_{score} \gets 0.3 \times A[v].ports + 0.4 \times A[v].services$
    \State \hspace{2.3cm} $+ 0.3 \times A[v].vulnerabilities$
    \State $weighted_{score} \gets local_{score} \times centrality[v]$
    \State $ASSA_{score} \gets ASSA_{score} + weighted_{score}$
\EndFor
\State \Return $ASSA_{score}$
\end{algorithmic}
\end{algorithm}

\textbf{Analisi di complessità:} La complessità computazionale è dominata dal calcolo della betweenness centrality, che richiede $O(|V|^2 \times |E|)$ nel caso generale. Per grafi sparsi tipici delle reti GDO, la complessità si riduce a $O(|V|^2 \log |V|)$.

\subsection{C.1.2 Algoritmo di Ottimizzazione Compliance}

\begin{algorithm}
\caption{Ottimizzazione Set-Covering per Compliance Integrata}
\label{alg:compliance}
\begin{algorithmic}
\Require Requisiti $R$, Controlli $C$, Funzione costo $cost$
\Ensure $S$ - insieme ottimale di controlli
\State $S \gets \emptyset$
\State $Uncovered \gets R$
\While{$Uncovered \neq \emptyset$}
    \State $best_{ratio} \gets \infty$
    \State $best_{control} \gets null$
    \ForAll{$c \in C \setminus S$}
        \State $coverage \gets |covers(c) \cap Uncovered|$
        \If{$coverage > 0$}
            \State $ratio \gets cost[c] / coverage$
            \If{$ratio < best_{ratio}$}
                \State $best_{ratio} \gets ratio$
                \State $best_{control} \gets c$
            \EndIf
        \EndIf
    \EndFor
    \State $S \gets S \cup \{best_{control}\}$
    \State $Uncovered \gets Uncovered \setminus covers(best_{control})$
\EndWhile
\State \Return $S$
\end{algorithmic}
\end{algorithm}

\textbf{Analisi di complessità:} L'algoritmo greedy ha complessità $O(|C| \times |R|^2)$ dove $|C|$ è il numero di controlli e $|R|$ il numero di requisiti. La fase di ottimizzazione locale aggiunge $O(|C|^2)$ nel caso peggiore.

\subsection{C.1.3 Calcolo del Framework GIST Score}

\begin{algorithm}
\caption{Calcolo GIST Score}
\label{alg:gist}
\begin{algorithmic}
\Require Componenti $comp$, Pesi $w$, Contesto $ctx$
\Ensure $GIST_{score}$ normalizzato in [0,100]
\State \textbf{// Calcolo score base con modello aggregato}
\State $score_{base} \gets 0$
\ForAll{$i \in \{Physical, Architectural, Security, Compliance\}$}
    \State $score_{base} \gets score_{base} + w_i \times comp_i$
\EndFor
\State \textbf{// Calcolo fattore di contesto GDO}
\State $K_{GDO} \gets 1.0$
\State $K_{GDO} \gets K_{GDO} \times (1 + 0.15 \times \log(\max(1, ctx.stores/50)))$
\State $K_{GDO} \gets K_{GDO} \times (1 + 0.08 \times (ctx.regions - 1))$
\State $K_{GDO} \gets K_{GDO} \times 1.25$ \Comment{Fattore criticità retail}
\State \textbf{// Fattore innovazione}
\State $I \gets ctx.innovation\mathit{level} \in [0, 0.35]$
\State \textbf{// Score finale}
\State $GIST_{score} \gets score_{base} \times K_{GDO} \times (1 + I) \times 100$
\State \Return $GIST_{score}$
\end{algorithmic}
\end{algorithm}

\section{C.2 Modelli Matematici Dettagliati}

\subsection{C.2.1 Modello di Evoluzione Infrastrutturale}

Il modello di evoluzione infrastrutturale è formalizzato come:

\begin{equation}
E(t) = \alpha \cdot I(t-1) + \beta \cdot T(t) + \gamma \cdot C(t) + \delta \cdot R(t) + \varepsilon
\label{eq:evolution}
\end{equation}

dove:
\begin{itemize}
    \item $I(t-1)$: Stato dell'infrastruttura al tempo $t-1$ (path dependency)
    \item $T(t)$: Pressione tecnologica = $f(\text{innovazione\_settore}, \text{maturità\_tecnologie})$
    \item $C(t)$: Vincoli di compliance = $g(\text{normative\_attive}, \text{sanzioni\_medie})$
    \item $R(t)$: Requisiti di resilienza = $h(\text{SLA\_target}, \text{criticità\_business})$
    \item $\varepsilon \sim \mathcal{N}(0, \sigma^2)$: Termine di errore gaussiano
\end{itemize}

\paragraph{Calibrazione dei parametri (OLS su 234 osservazioni):}
\begin{align}
\alpha &= 0.42 \quad (SE = 0.04, \; p < 0.001) \\
\beta &= 0.28 \quad (SE = 0.03, \; p < 0.001) \\
\gamma &= 0.18 \quad (SE = 0.03, \; p < 0.001) \\
\delta &= 0.12 \quad (SE = 0.02, \; p < 0.001)
\end{align}

Modello complessivo: $R^2 = 0.87$, $R^2_{adj} = 0.86$, $F(4,229) = 384.7$, $p < 0.001$

\subsection{C.2.2 Dimostrazione della Complessità Computazionale}

\begin{theorem}
L'algoritmo GDO-Cloud ottimizzato ha complessità $O(n \log n)$ dove $n$ è il numero di workload da migrare.
\end{theorem}

\begin{proof}
L'algoritmo si compone di quattro fasi principali:
\begin{enumerate}
    \item \textbf{Partizionamento workload}: Utilizzo di hash-based partitioning con complessità $O(n)$
    \item \textbf{Ordinamento per priorità}: Heap sort con complessità $O(n \log n)$
    \item \textbf{Assegnazione greedy}: Singola scansione con complessità $O(n)$
    \item \textbf{Bilanciamento finale}: Nel caso peggiore richiede riordinamento, quindi $O(n \log n)$
\end{enumerate}

La complessità totale è quindi:
$$T(n) = O(n) + O(n \log n) + O(n) + O(n \log n) = O(n \log n)$$

Questo rappresenta un miglioramento significativo rispetto all'approccio naive $O(n^3)$ basato su programmazione dinamica completa. \qed
\end{proof}

\subsection{C.2.3 Modello Stocastico per Analisi TCO}

Il Total Cost of Ownership per migrazione cloud è modellato come:

\begin{equation}
TCO_{5y} = M_{cost} \times \text{Triang}(0.8, 1.06, 1.3) + \sum_{t=1}^{5} \frac{OPEX_t \times (1 - r_s)}{(1 + d)^t}
\label{eq:tco}
\end{equation}

dove:
\begin{itemize}
    \item $M_{cost}$: Costo di migrazione iniziale
    \item $\text{Triang}(a,b,c)$: Distribuzione triangolare per incertezza
    \item $r_s \sim \text{Triang}(0.28, 0.39, 0.45)$: Saving operativi
    \item $d = 0.08$: Tasso di sconto annuale
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDICE D - MATERIALE SUPPLEMENTARE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Materiale Supplementare}
\label{app:supplementare}

\section{D.1 Glossario degli Acronimi}

\begin{table}[htbp]
\centering
\caption{Glossario degli acronimi utilizzati nella tesi}
\label{tab:glossario}
\begin{tabular}{llc}
\toprule
\textbf{Acronimo} & \textbf{Significato} & \textbf{Prima occorrenza} \\
\midrule
AIOps & Artificial Intelligence for IT Operations & Cap. 3, pag. 28 \\
ASSA & Aggregated System Surface Attack & Cap. 2, pag. 8 \\
CAPEX & Capital Expenditure & Cap. 1, pag. 2 \\
CFD & Computational Fluid Dynamics & Cap. 3, pag. 20 \\
CMMI & Capability Maturity Model Integration & Cap. 4, pag. 34 \\
EDR & Endpoint Detection and Response & Cap. 2, pag. 8 \\
ESG & Environmental, Social, and Governance & Cap. 5, pag. 57 \\
GDO & Grande Distribuzione Organizzata & Cap. 1, pag. 1 \\
GDPR & General Data Protection Regulation & Cap. 1, pag. 2 \\
GIST & GDO Integrated Security Transformation & Cap. 1, pag. 3 \\
HVAC & Heating, Ventilation, and Air Conditioning & Cap. 1, pag. 2 \\
IAM & Identity and Access Management & Cap. 5, pag. 50 \\
IDS/IPS & Intrusion Detection/Prevention System & Cap. 2, pag. 13 \\
IoT & Internet of Things & Cap. 2, pag. 10 \\
IRR & Internal Rate of Return & Cap. 5, pag. 49 \\
KPI & Key Performance Indicator & Cap. 5, pag. 52 \\
ML & Machine Learning & Cap. 3, pag. 20 \\
MTBF & Mean Time Between Failures & Cap. 3, pag. 21 \\
MTTR & Mean Time To Repair & Cap. 3, pag. 22 \\
NFC & Near Field Communication & Cap. 2, pag. 12 \\
NIS2 & Network and Information Security Directive 2 & Cap. 1, pag. 2 \\
NPV & Net Present Value & Cap. 3, pag. 24 \\
OPEX & Operational Expenditure & Cap. 1, pag. 2 \\
OT & Operational Technology & Cap. 1, pag. 1 \\
PCI-DSS & Payment Card Industry Data Security Standard & Cap. 1, pag. 2 \\
POS & Point of Sale & Cap. 2, pag. 8 \\
PSIM & Physical Security Information Management & Cap. 5, pag. 55 \\
PUE & Power Usage Effectiveness & Cap. 3, pag. 20 \\
ROI & Return on Investment & Cap. 1, pag. 2 \\
SASE & Secure Access Service Edge & Cap. 3, pag. 30 \\
SCADA & Supervisory Control and Data Acquisition & Cap. 4, pag. 35 \\
SD-WAN & Software-Defined Wide Area Network & Cap. 3, pag. 22 \\
SIEM & Security Information and Event Management & Cap. 2, pag. 15 \\
SIR & Susceptible-Infected-Recovered & Cap. 2, pag. 12 \\
SLA & Service Level Agreement & Cap. 1, pag. 4 \\
SOC & Security Operations Center & Cap. 5, pag. 51 \\
SSE & Security Service Edge & Cap. 3, pag. 30 \\
TCO & Total Cost of Ownership & Cap. 1, pag. 2 \\
UPS & Uninterruptible Power Supply & Cap. 3, pag. 20 \\
VaR & Value at Risk & Cap. 4, pag. 32 \\
VLAN & Virtual Local Area Network & Cap. 3, pag. 22 \\
VPN & Virtual Private Network & Cap. 3, pag. 22 \\
WAN & Wide Area Network & Cap. 3, pag. 22 \\
ZTNA & Zero Trust Network Access & Cap. 2, pag. 13 \\
\bottomrule
\end{tabular}
\end{table}

\section{D.2 Assunzioni del Modello}

\subsection{D.2.1 Assunzioni Tecniche}

\begin{enumerate}
    \item \textbf{Distribuzione latenza di rete}: Si assume distribuzione Gamma con parametri forma=2, scala=2ms basata su misurazioni empiriche
    \item \textbf{Tasso di guasto componenti}: Segue distribuzione di Weibull con parametri calibrati su dati storici MTBF
    \item \textbf{Indipendenza guasti}: Si assume indipendenza statistica tra guasti di componenti ridondanti
    \item \textbf{Crescita volume dati}: 35\% annuo basato su trend settore retail 2020-2024
    \item \textbf{Efficacia controlli di sicurezza}: Riduzione lineare del rischio proporzionale alla copertura
\end{enumerate}

\subsection{D.2.2 Assunzioni Economiche}

\begin{enumerate}
    \item \textbf{Tasso di sconto}: 8\% annuo per calcoli NPV, basato su WACC medio del settore
    \item \textbf{Inflazione IT}: 3.5\% annuo per hardware, 2\% per servizi cloud (fonte: IDC)
    \item \textbf{Costo del downtime}: 15.000€/ora per punto vendita medio, basato su survey di settore
    \item \textbf{Turnover personale}: 75\% annuo per personale operativo di punto vendita
    \item \textbf{Vita utile investimenti}: 5 anni per hardware, 3 anni per software
\end{enumerate}

\section{D.3 Limitazioni dello Studio}

\subsection{D.3.1 Limitazioni Metodologiche}

\begin{itemize}
    \item \textbf{Dimensione del modello}: Il modello rappresenta diverse tipologie di organizzazioni che coprono circa il 3\% del mercato italiano GDO per fatturato. La simulazione potrebbe non catturare tutte le variabilità del settore.
    
    \item \textbf{Durata dello studio}: Il periodo di 24 mesi potrebbe non essere sufficiente per osservare effetti a lungo termine, particolarmente quelli legati a cambiamenti culturali organizzativi.
    
    \item \textbf{Focus geografico}: La concentrazione su organizzazioni italiane limita la generalizzabilità a contesti con differenti framework normativi o caratteristiche di mercato.
    
    \item \textbf{Survivor bias}: Le organizzazioni partecipanti sono quelle che hanno completato con successo la trasformazione, escludendo potenziali fallimenti.
\end{itemize}

\subsection{D.3.2 Limitazioni Tecniche}

\begin{itemize}
    \item \textbf{Simulazioni Monte Carlo}: Assumono distribuzioni parametriche che potrebbero semplificare la complessità reale
    \item \textbf{Modello GIST}: Assume relazioni lineari tra componenti che potrebbero essere non-lineari
    \item \textbf{Metriche di sicurezza}: ASSA è una proxy della superficie di attacco, non una misura diretta del rischio
    \item \textbf{Dati self-reported}: Alcune metriche si basano su valutazioni soggettive delle organizzazioni
\end{itemize}

\section{D.4 Informazioni per la Riproducibilità}

\subsection{D.4.1 Software e Versioni Utilizzate}

\begin{itemize}
    \item \textbf{Analisi statistica}: R v4.3.1 con pacchetti: tidyverse 2.0.0, lme4 1.1-34, car 3.1-2
    \item \textbf{Simulazioni}: Python 3.11.4 con numpy 1.24.3, scipy 1.11.1, pandas 2.0.3
    \item \textbf{Visualizzazioni}: matplotlib 3.7.2, seaborn 0.12.2, ggplot2 3.4.3
    \item \textbf{Documentazione}: LaTeX con pacchetti algorithmic, booktabs, tikz
\end{itemize}

\subsection{D.4.2 Disponibilità Dati e Codice}

Per garantire la riproducibilità della ricerca, i seguenti materiali sono disponibili su richiesta:

\begin{itemize}
    \item \textbf{Dataset anonimizzato}: Disponibile previa firma di NDA per protezione dati commerciali sensibili
    \item \textbf{Script di analisi}: Repository GitHub (URL da definire post-pubblicazione)
    \item \textbf{Template assessment}: Questionari e checklist in formato editabile
\end{itemize}

\textbf{Contatto per richieste}: \\
Email: marco.santoro@universita.it \\
ORCID: 0000-0000-0000-0000 (da assegnare)

\vspace{1cm}

\noindent\rule{\textwidth}{0.4pt}

\textit{Nota finale}: Le appendici sono state progettate per fornire tutti i dettagli tecnici necessari alla comprensione e replicazione dello studio, mantenendo un equilibrio tra completezza e concisione appropriato per una tesi di laurea triennale in Ingegneria Informatica.