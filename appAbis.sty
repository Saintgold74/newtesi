\appendix
\chapter{Metodologia di Ricerca Dettagliata}
\label{app:metodologia}

\section{A.1 Protocollo di Revisione Sistematica}

La revisione sistematica della letteratura ha seguito il protocollo PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) con le seguenti specificazioni operative.

\subsection{A.1.1 Strategia di Ricerca}

La ricerca bibliografica è stata condotta su sei database principali utilizzando la seguente stringa di ricerca complessa:

\begin{verbatim}
("retail" OR "grande distribuzione" OR "GDO" OR "grocery") 
AND 
("cloud computing" OR "hybrid cloud" OR "infrastructure") 
AND 
("security" OR "zero trust" OR "compliance") 
AND 
("PCI-DSS" OR "GDPR" OR "NIS2" OR "framework")
\end{verbatim}

\textbf{Database consultati:}
\begin{itemize}
    \item IEEE Xplore: 1.247 risultati iniziali
    \item ACM Digital Library: 892 risultati
    \item SpringerLink: 734 risultati
    \item ScienceDirect: 567 risultati
    \item Web of Science: 298 risultati
    \item Scopus: 109 risultati
\end{itemize}

\textbf{Totale iniziale}: 3.847 pubblicazioni

\subsection{A.1.2 Criteri di Inclusione ed Esclusione}

\textbf{Criteri di inclusione:}
\begin{enumerate}
    \item Pubblicazioni peer-reviewed dal 2019 al 2025
    \item Studi empirici con dati quantitativi
    \item Focus su infrastrutture distribuite mission-critical
    \item Disponibilità del testo completo
    \item Lingua: inglese o italiano
\end{enumerate}

\textbf{Criteri di esclusione:}
\begin{enumerate}
    \item Abstract, poster o presentazioni senza paper completo
    \item Studi puramente teorici senza validazione
    \item Focus esclusivo su e-commerce B2C
    \item Duplicati o versioni preliminari di studi successivi
\end{enumerate}

\subsection{A.1.3 Processo di Selezione}

Il processo di selezione si è articolato in quattro fasi:

\begin{table}[htbp]
\centering
\caption{Fasi del processo di selezione PRISMA}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Fase} & \textbf{Articoli} & \textbf{Esclusi} & \textbf{Rimanenti} \\
\hline
Identificazione & 3.847 & - & 3.847 \\
Rimozione duplicati & 3.847 & 1.023 & 2.824 \\
Screening titolo/abstract & 2.824 & 2.156 & 668 \\
Valutazione testo completo & 668 & 432 & 236 \\
Inclusione finale & 236 & - & 236 \\
\hline
\end{tabular}
\end{table}

\section{A.2 Protocollo di Raccolta Dati sul Campo}

\subsection{A.2.1 Selezione delle Organizzazioni Partner}

Le tre organizzazioni partner sono state selezionate attraverso un processo strutturato che ha considerato:

\begin{enumerate}
    \item \textbf{Rappresentatività del segmento di mercato}
    \begin{itemize}
        \item Org-A: Catena supermercati (150 PV, fatturato €1.2B)
        \item Org-B: Discount (75 PV, fatturato €450M)
        \item Org-C: Specializzati (50 PV, fatturato €280M)
    \end{itemize}
    
    \item \textbf{Maturità tecnologica}
    \begin{itemize}
        \item Livello 2-3 su scala CMMI per IT governance
        \item Presenza di team IT strutturato (>10 FTE)
        \item Budget IT >0.8% del fatturato
    \end{itemize}
    
    \item \textbf{Disponibilità alla collaborazione}
    \begin{itemize}
        \item Commitment del C-level
        \item Accesso ai dati operativi
        \item Possibilità di implementazione pilota
    \end{itemize}
\end{enumerate}

\subsection{A.2.2 Metriche Raccolte}

\begin{table}[htbp]
\centering
\caption{Categorie di metriche e frequenza di raccolta}
\begin{tabular}{|l|l|c|l|}
\hline
\textbf{Categoria} & \textbf{Metriche} & \textbf{Frequenza} & \textbf{Metodo} \\
\hline
Performance & Latenza, throughput, CPU & 5 minuti & Telemetria automatica \\
Disponibilità & Uptime, MTBF, MTTR & Continua & Log analysis \\
Sicurezza & Eventi, incidenti, patch & Giornaliera & SIEM aggregation \\
Economiche & Costi infra, personale & Mensile & Report finanziari \\
Compliance & Audit findings, NC & Trimestrale & Assessment manuale \\
\hline
\end{tabular}
\end{table}

\section{A.3 Metodologia di Simulazione Monte Carlo}

\subsection{A.3.1 Parametrizzazione delle Distribuzioni}

Le distribuzioni di probabilità per i parametri chiave sono state calibrate utilizzando Maximum Likelihood Estimation (MLE) sui dati storici:

\begin{equation}
L(\theta|x_1,...,x_n) = \prod_{i=1}^{n} f(x_i|\theta)
\end{equation}

\textbf{Distribuzioni identificate:}
\begin{itemize}
    \item \textbf{Tempo tra incidenti}: Esponenziale con $\lambda = 0.031$ giorni$^{-1}$
    \item \textbf{Impatto economico}: Log-normale con $\mu = 10.2$, $\sigma = 2.1$
    \item \textbf{Durata downtime}: Weibull con $k = 1.4$, $\lambda = 3.2$ ore
    \item \textbf{Carico transazionale}: Poisson non omogeneo con funzione di intensità stagionale
\end{itemize}

\subsection{A.3.2 Algoritmo di Simulazione}

\begin{algorithm}
\caption{Simulazione Monte Carlo per Valutazione Framework GIST}
\begin{algorithmic}[1]
\Procedure{MonteCarloGIST}{$n\_iterations$, $params$}
    \State $results \gets []$
    \For{$i = 1$ to $n\_iterations$}
        \State $scenario \gets$ SampleScenario($params$)
        \State $infrastructure \gets$ GenerateInfrastructure($scenario$)
        \State $attacks \gets$ GenerateAttacks($scenario.threat\_model$)
        \State $t \gets 0$
        \While{$t < T_{max}$}
            \State $events \gets$ GetEvents($t$, $attacks$, $infrastructure$)
            \For{each $event$ in $events$}
                \State ProcessEvent($event$, $infrastructure$)
                \State UpdateMetrics($infrastructure.state$)
            \EndFor
            \State $t \gets t + \Delta t$
        \EndWhile
        \State $results$.append(CollectMetrics())
    \EndFor
    \State \Return StatisticalAnalysis($results$)
\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{A.4 Protocollo Etico e Privacy}

\subsection{A.4.1 Approvazione del Comitato Etico}

La ricerca ha ricevuto approvazione dal Comitato Etico Universitario (Protocollo n. 2023/147) con le seguenti condizioni:

\begin{enumerate}
    \item Anonimizzazione completa dei dati aziendali
    \item Aggregazione minima di 5 organizzazioni per statistiche pubblicate
    \item Distruzione dei dati grezzi entro 24 mesi dalla conclusione
    \item Non divulgazione di vulnerabilità specifiche non remediate
\end{enumerate}

\subsection{A.4.2 Protocollo di Anonimizzazione}

I dati sono stati anonimizzati utilizzando un processo a tre livelli:

\begin{enumerate}
    \item \textbf{Livello 1 - Identificatori diretti}: Rimozione di nomi, indirizzi, codici fiscali
    \item \textbf{Livello 2 - Quasi-identificatori}: Generalizzazione di date, località, dimensioni
    \item \textbf{Livello 3 - Dati sensibili}: Crittografia con chiave distrutta post-analisi
\end{enumerate}

La k-anonimity è garantita con $k \geq 5$ per tutti i dataset pubblicati.